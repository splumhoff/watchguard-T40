WatchGuard patches to sources for ixgbe-5.9.4 as of
Mon May  9 13:54:33 PDT 2022
The patches shown here have been applied to source .tar.gz 
files supplied with the WatchGuard Open Source Archive.

==========================================================================
--- ixgbe-5.9.4/src/ixgbe_lib.c.orig	2022-05-09 13:54:32.065991539 -0700
+++ ixgbe-5.9.4/src/ixgbe_lib.c	2022-05-09 13:54:32.153987969 -0700
@@ -674,6 +674,45 @@
 	return true;
 }
 
+#ifdef	CONFIG_WG_PLATFORM // WG:JB Limit RSS if we have too many CPUs
+#define WG_M5800_MAX_RSS_INDICES	8	// WG:XD FBX-19073
+// Return how many RSS queus we should have
+u8 wg_max_rss(struct ixgbe_adapter *adapter, int q)
+{
+	int k = num_online_cpus();
+
+	// If we don't have too many CPUs, return passed value
+	if (q >= k)
+		return q;
+
+	// WG:XD FBX-19073
+	if (adapter->hw.mac.type == ixgbe_mac_82599EB && k > IXGBE_MAX_RSS_INDICES) {
+		if (wg_cpu_model == WG_CPU_686(6230)) {
+			k = WG_M5800_MAX_RSS_INDICES;
+			adapter->ring_feature[RING_F_FDIR].limit = WG_M5800_MAX_RSS_INDICES;
+		} else {
+			k = IXGBE_MAX_RSS_INDICES;
+			adapter->ring_feature[RING_F_FDIR].limit = IXGBE_MAX_RSS_INDICES;
+		}
+		printk(KERN_INFO "@@ %s: %s max rss indices set to: %u\n",
+			   __FUNCTION__, adapter->netdev->name, adapter->ring_feature[RING_F_FDIR].limit);
+		return k;
+	}
+
+	// Too many CPUs, try to divide into groups
+	while (k > q)
+		if ((k % 2) == 0) k /= 2; else
+		if ((k % 3) == 0) k /= 3; else
+		if ((k % 5) == 0) k /= 5; else
+		if ((k % 7) == 0) k /= 7; else	k = q;
+
+	if (000&000)
+		printk(KERN_DEBUG "%s: MAC Max %d RSS %d\n", __FUNCTION__, q, k);
+
+	return k;
+}
+#endif
+
 /**
  * ixgbe_set_rss_queues: Allocate queues for RSS
  * @adapter: board private structure to initialize
@@ -692,6 +731,12 @@
 	f = &adapter->ring_feature[RING_F_RSS];
 	rss_i = f->limit;
 
+#ifdef	CONFIG_WG_PLATFORM // WG:JB Limit RSS if we have too many CPUs
+	if (rss_i < num_online_cpus())
+		printk(KERN_INFO "ixgbe %s: rss limited to %2d\n",
+			   adapter->netdev->name, rss_i);
+#endif
+
 	f->indices = rss_i;
 	if (hw->mac.type < ixgbe_mac_X550)
 		f->mask = IXGBE_RSS_16Q_MASK;
--- ixgbe-5.9.4/src/ixgbe_82599.c.orig	2022-05-09 13:54:31.957995920 -0700
+++ ixgbe-5.9.4/src/ixgbe_82599.c	2022-05-09 13:54:32.141988455 -0700
@@ -1004,8 +1004,17 @@
 
 	/* Call adapter stop to disable tx/rx and clear interrupts */
 	status = hw->mac.ops.stop_adapter(hw);
+#ifdef CONFIG_WG_PLATFORM // WG:XD FBX-2063 do extra reset, ref. intel errata
+	if (status != IXGBE_SUCCESS) {
+		printk(KERN_WARNING "@@ issuing 2nd reset cmd ...\n");
+		IXGBE_WRITE_REG(hw, IXGBE_CTRL, IXGBE_CTRL_RST);
+		IXGBE_WRITE_FLUSH(hw);
+		printk(KERN_WARNING "@@ done sending 2nd reset cmd\n");
+	}
+#else
 	if (status != IXGBE_SUCCESS)
 		goto reset_hw_out;
+#endif
 
 	/* flush pending Tx transactions */
 	ixgbe_clear_tx_pending(hw);
--- ixgbe-5.9.4/src/ixgbe_ethtool.c.orig	2022-05-09 13:54:32.029992999 -0700
+++ ixgbe-5.9.4/src/ixgbe_ethtool.c	2022-05-09 13:54:32.149988131 -0700
@@ -270,10 +270,16 @@
 
 	hw->mac.ops.get_link_capabilities(hw, &supported_link, &autoneg);
 	/* set the supported link speeds */
+
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+#if (!defined(CONFIG_WG_PLATFORM_M290_T80) && !defined(CONFIG_WG_PLATFORM_M390) && \
+     !defined(CONFIG_WG_PLATFORM_M590_M690))	// for castlerock platforms
 	if (supported_link & IXGBE_LINK_SPEED_10GB_FULL) {
 		ixgbe_set_supported_10gtypes(hw, cmd);
 		ixgbe_set_advertising_10gtypes(hw, cmd);
 	}
+#endif
 #ifdef HAVE_ETHTOOL_5G_BITS
 	if (supported_link & IXGBE_LINK_SPEED_5GB_FULL)
 		ethtool_link_ksettings_add_link_mode(cmd, supported,
@@ -319,8 +325,13 @@
 		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_100_FULL)
 			ethtool_link_ksettings_add_link_mode(cmd, advertising,
 							     100baseT_Full);
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+#if (!defined(CONFIG_WG_PLATFORM_M290_T80) && !defined(CONFIG_WG_PLATFORM_M390) && \
+     !defined(CONFIG_WG_PLATFORM_M590_M690))	// for castlerock platforms
 		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_10GB_FULL)
 			ixgbe_set_advertising_10gtypes(hw, cmd);
+#endif
 		if (hw->phy.autoneg_advertised & IXGBE_LINK_SPEED_1GB_FULL) {
 			if (ethtool_link_ksettings_test_link_mode
 				(cmd, supported, 1000baseKX_Full))
@@ -1662,6 +1673,13 @@
 			       IXGBE_MIN_RXD, IXGBE_MAX_RXD);
 	new_rx_count = ALIGN(new_rx_count, IXGBE_REQ_RX_DESCRIPTOR_MULTIPLE);
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+	if ((has88E6190) && ((new_tx_count > 256) || (new_rx_count > 256)))
+		wg_dsa_sgmii_poll = &wg_ixgbe_sgmii_poll;
+	else
+		wg_dsa_sgmii_poll = NULL;;
+#endif
+
 	if ((new_tx_count == adapter->tx_ring_count) &&
 	    (new_rx_count == adapter->rx_ring_count)) {
 		/* nothing to do */
--- ixgbe-5.9.4/src/ixgbe_phy.c.orig	2022-05-09 13:54:32.085990727 -0700
+++ ixgbe-5.9.4/src/ixgbe_phy.c	2022-05-09 13:54:32.157987806 -0700
@@ -3,6 +3,9 @@
 
 #include "ixgbe_api.h"
 #include "ixgbe_common.h"
+#ifdef CONFIG_WG_PLATFORM  // WG XD FBX-5815
+#include "ixgbe.h"
+#endif
 #include "ixgbe_phy.h"
 
 STATIC void ixgbe_i2c_start(struct ixgbe_hw *hw);
@@ -207,6 +210,345 @@
 	return IXGBE_ERR_I2C;
 }
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)  // WG:JB Marvell 88E6190 init code
+
+#include <linux/phy.h>
+
+#ifdef	CONFIG_WG_PLATFORM_DSA_MODULE
+extern	struct mii_bus*  wg_dsa_bus;
+#else
+static	struct mii_bus*  wg_dsa_bus;
+#endif
+
+static	struct ixgbe_hw* wg_dsa_hw;
+
+static	       atomic_t	 wg_dsa_mdio_users = ATOMIC_INIT(0);
+
+#define	TOKEN_MDIO	(wg_dsa_hw->phy.phy_semaphore_mask | IXGBE_GSSR_TOKEN_SM)
+
+void wg_ixgbe_swfw_sync_acquire(void)
+{
+	int n = atomic_inc_return(&wg_dsa_mdio_users);
+
+	if	   (unlikely(n <= 0)) {
+		if (unlikely(n <  0)) {
+			atomic_set(&wg_dsa_mdio_users,  0);
+			printk(KERN_EMERG "%s: count %d\n", __FUNCTION__, n);
+		}
+
+		atomic_inc_return(&wg_dsa_mdio_users);
+
+		if (unlikely(wg_dsa_hw->mac.ops.acquire_swfw_sync(wg_dsa_hw, TOKEN_MDIO)))
+			printk(KERN_EMERG "%s: failed\n",   __FUNCTION__);
+		else
+
+		if (unlikely(wg_dsa_debug & 0x400))
+			printk(KERN_DEBUG "%s: success\n",  __FUNCTION__);
+	}
+}
+
+void wg_ixgbe_swfw_sync_release(void)
+{
+	int n = atomic_dec_return(&wg_dsa_mdio_users);
+
+	if	   (unlikely(n <  0)) {
+		if (unlikely(n < -1)) {
+			atomic_set(&wg_dsa_mdio_users, -1);
+			printk(KERN_EMERG "%s: count %d\n", __FUNCTION__, n);
+		}
+
+		wg_dsa_hw->mac.ops.release_swfw_sync(wg_dsa_hw, TOKEN_MDIO);
+
+		if (unlikely(wg_dsa_debug & 0x400))
+			printk(KERN_DEBUG "%s: success\n",  __FUNCTION__);
+	}
+}
+
+DEFINE_SEMAPHORE(wg_dsa_sem);
+
+void wg_ixgbe_mdio_release(void)
+{
+	down(&wg_dsa_sem);
+
+	if (atomic_read(&wg_dsa_mdio_users) >= 0)
+		wg_ixgbe_swfw_sync_release();
+
+	up(&wg_dsa_sem);
+}
+
+int wg_ixgbe_raw_phy_read (struct mii_bus* _bus, int phy_id, int reg_num)
+{
+	int err;
+	int phy = wg_dsa_hw->phy.addr;
+	u16 val = 0xDEAD;
+
+	wg_dsa_hw->phy.addr = DSA_PHY_MAP(phy_id);
+
+// WG:JB Use clause 22 code in ixgbe_x550.c
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+	down(&wg_dsa_sem);
+	wg_ixgbe_swfw_sync_acquire();
+	err = wg_dsa_hw->phy.ops.read_reg_mdi(wg_dsa_hw, reg_num, 0, &val);
+	wg_ixgbe_swfw_sync_release();
+	up(&wg_dsa_sem);
+#else
+	err = wg_dsa_hw->phy.ops.read_reg(wg_dsa_hw, reg_num, 0, &val);
+#endif
+	wg_dsa_hw->phy.addr = phy;
+	if (unlikely(err || (wg_dsa_debug & 0x200)))
+	printk(KERN_EMERG "%s:  phy %2d reg %2d val %4x err %d\n",
+	       __FUNCTION__, phy_id, reg_num, val, err);
+	if (err < 0) return err;
+	return val;
+}
+
+int wg_ixgbe_raw_phy_write(struct mii_bus* _bus, int phy_id, int reg_num, u16 val)
+{
+	int err;
+	int phy = wg_dsa_hw->phy.addr;
+
+	wg_dsa_hw->phy.addr = DSA_PHY_MAP(phy_id);
+
+// WG:JB Use clause 22 code in ixgbe_x550.c
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) 
+	down(&wg_dsa_sem);
+	wg_ixgbe_swfw_sync_acquire();
+	err = wg_dsa_hw->phy.ops.write_reg_mdi(wg_dsa_hw, reg_num, 0, val);
+	wg_ixgbe_swfw_sync_release();
+	up(&wg_dsa_sem);
+#else
+	err = wg_dsa_hw->phy.ops.write_reg(wg_dsa_hw, reg_num, 0, val);
+#endif
+	wg_dsa_hw->phy.addr = phy;
+	if (unlikely(err || (wg_dsa_debug & 0x200)))
+	printk(KERN_EMERG "%s: phy %2d reg %2d val %4x err %d\n",
+	       __FUNCTION__, phy_id, reg_num, val, err);
+	if (err < 0) return err;
+	return val;
+}
+
+static int wg_ixgbe_wait(void)
+{
+	int j;
+	int val;
+
+	for (j = 10; --j >= 0; usec_delay(10))
+	if (((val = wg_ixgbe_raw_phy_read(wg_dsa_bus, 28, 24)) & 0x8000) == 0) return val;
+
+	printk(KERN_EMERG "%s: stuck value %4x\n", __FUNCTION__, val);
+
+	atomic_set(&wg_dsa_mdio_users, -1);
+	wg_ixgbe_swfw_sync_release();
+
+	return -ETIMEDOUT;
+}
+
+int wg_ixgbe_op_phy_read (struct mii_bus* _bus, int op, int phy, int reg)
+{
+	if (phy >= 16) return wg_ixgbe_raw_phy_read (wg_dsa_bus, phy, reg);
+
+	if (unlikely(wg_ixgbe_wait() < 0)) return -ETIMEDOUT;
+	wg_ixgbe_raw_phy_write(wg_dsa_bus, 28, 24, 0x8800 | (op << 10) | (DSA_PHY_MAP(phy) << 5) | reg);
+	if (unlikely(wg_ixgbe_wait() < 0)) return -ETIMEDOUT;
+
+	return wg_ixgbe_raw_phy_read(wg_dsa_bus, 28, 25);
+}
+
+int wg_ixgbe_op_phy_write(struct mii_bus* _bus, int op, int phy, int reg, u16 val)
+{
+	if (phy >= 16) return wg_ixgbe_raw_phy_write(wg_dsa_bus, phy, reg, val);
+
+	if (unlikely(wg_ixgbe_wait() < 0)) return -ETIMEDOUT;
+	wg_ixgbe_raw_phy_write(wg_dsa_bus, 28, 25, val);
+	wg_ixgbe_raw_phy_write(wg_dsa_bus, 28, 24, 0x8000 | (op << 10) | (DSA_PHY_MAP(phy) << 5) | reg);
+	if (unlikely(wg_ixgbe_wait() < 0)) return -ETIMEDOUT;
+
+	return val;
+}
+
+int wg_ixgbe_phy_read (struct mii_bus* _bus, int phy, int reg)
+{
+	return wg_ixgbe_op_phy_read (_bus, 4|2, phy, reg);      // Or in 4 to set clause 22
+}
+
+int wg_ixgbe_phy_write(struct mii_bus* _bus, int phy, int reg, u16 val)
+{
+	return wg_ixgbe_op_phy_write(_bus, 4|1, phy, reg, val); // Or in 4 to set clause 22
+}
+
+static int wg_ixgbe_get_phy_id(int phy)
+{
+	int id1 = wg_ixgbe_phy_read(wg_dsa_bus, phy, 2);
+	int id2 = wg_ixgbe_phy_read(wg_dsa_bus, phy, 3);
+
+	printk(KERN_EMERG "%s:  phy %2d id %4x %4x\n", __FUNCTION__, phy, id1, id2);
+
+	return (id1<<16) | id2;
+}
+
+void wg_ixgbe_phy_soft_reset(void)
+{
+	wg_dsa_hw->phy.addr = 27;
+	wg_dsa_hw->phy.ops.write_reg_mdi(wg_dsa_hw, 0x04, 0, 0xC001);
+	printk(KERN_EMERG "%s: 88E6190 soft reset\n", __FUNCTION__);
+	msec_delay(100);
+}
+	
+int  wg_ixgbe_sgmii_init(int j)
+{
+	int k;
+	u16 value;
+
+	wg_ixgbe_phy_write(wg_dsa_bus,			     j|16, 4, 0x007C);
+	usec_delay(1000);
+
+	wg_ixgbe_phy_write(wg_dsa_bus,			     j|16, 1, 0x313F);
+
+	for (k = 10; --k >= 0;) {
+		wg_ixgbe_op_phy_write(wg_dsa_bus,	  0, j,    4, 0x2000);
+		wg_ixgbe_op_phy_write(wg_dsa_bus,	  1, j,    4, 0x8140);
+		value = wg_ixgbe_op_phy_read(wg_dsa_bus,  3, j,    4);
+
+		if (value == 0x0140) break;
+		usec_delay(1000);
+	}
+
+	wg_ixgbe_phy_write(wg_dsa_bus,			     j|16, 4, 0x007F);
+	usec_delay(10000);
+
+	printk(KERN_EMERG "%s: 88E6190 SGMII PHY%d Control %04X\n",
+	       __FUNCTION__, j, value);
+
+	return j;
+}
+
+int  wg_ixgbe_sgmii_poll(int j)
+{
+	int    k, q;
+	u16    value;
+	static u16 ned[2]       = {0, 0};
+	struct net_device*        netdev;
+	struct ixgbe_adapter*     adapter;
+	extern struct net_device* wg_dsa_dev[];
+
+	if (unlikely(!wg_dsa_bus)) return -ENXIO;
+
+	{
+	static long trace = 4;
+	if (--trace >= 0)
+	printk(KERN_EMERG "%s: 88E6190 SGMII PHY%d Poll\n", __FUNCTION__, j);
+	}
+
+	for (q = j & 1, j |= 8, k = 10; --k >= 0;)  {
+		wg_ixgbe_op_phy_write(wg_dsa_bus,	  0, j,    4, 0xA003);
+		value  = wg_ixgbe_op_phy_read(wg_dsa_bus, 3, j,    4);
+		value |= 0x0800;
+
+		if (value == 0xAC20) break;
+
+		ned[q] |= (value & 0x0010);
+
+		printk(KERN_EMERG "%s: 88E6190 SGMII PHY%d A003 %04X\n",
+		       __FUNCTION__, j, value);
+
+		usec_delay(10000);
+	}
+
+	if ((value |= ned[q]) == 0xAC20) return 0;
+
+	wg_ixgbe_sgmii_init(j);
+
+	if ((wg_dsa_sgmii_poll)		!= NULL)
+	if ((netdev = wg_dsa_dev[q])	!= NULL) {
+
+		printk(KERN_EMERG "%s: 88E6190 SGMII PHY%d Reset\n", __FUNCTION__, j);
+
+		ned[q] = 0;
+
+		adapter = netdev_priv(netdev);
+		ixgbe_reinit_locked(adapter);
+
+		usec_delay(10000);
+	}
+
+	return j;
+}
+
+void wg_ixgbe_phy_init(void)
+{
+	int j;
+	int m = 0x0200;
+
+	// Set up virtual to actual PHY mappings for 88E6190
+	for (j =  0; j < 10; j++)
+	wg_dsa_phy_map[ j] =   1;
+	wg_dsa_phy_map[10] = -10;
+	for (j = 16; j < 26; j++)
+	wg_dsa_phy_map[ j] = -15;
+	wg_dsa_phy_map[26] = -26;
+
+	// Disable ports
+	for (j = 0; j < 11; j++)
+	wg_ixgbe_phy_write(wg_dsa_bus, j|16, 4,      0x007C);
+	usec_delay(10000);
+
+	// Set up so all ports talk only to CPU
+	for (j = 0; j <  8; j++)
+	wg_ixgbe_phy_write(wg_dsa_bus, j|16, 6, m ^= 0x0600);
+
+	wg_ixgbe_phy_write(wg_dsa_bus, 8|16, 6,      0x0154);
+	wg_ixgbe_phy_write(wg_dsa_bus, 9|16, 6,      0x00AA);
+
+	// Display PHY Ids
+	for (j = 0; j <  8; j++)
+	wg_ixgbe_get_phy_id(j);
+
+	// Reset   extermal PHYs
+	for (j = 0; j <  8; j++)
+	wg_ixgbe_phy_write(wg_dsa_bus, j,    0,      0x9140);
+	usec_delay(10000);
+
+	// Enable  ports
+	for (j = 0; j < 10; j++)
+	wg_ixgbe_phy_write(wg_dsa_bus, j|16, 4,      0x007F);
+	usec_delay(10000);
+}
+
+int ixgbe_init_88E6190(struct ixgbe_hw *hw)
+{
+	if (!wg_dsa_bus) {
+
+		printk(KERN_EMERG "%s: Device ID: %x\n",
+		       __FUNCTION__, hw->device_id);
+
+		if (!(wg_dsa_bus = mdiobus_alloc())) {
+			printk(KERN_EMERG "%s: mii bus alloc failed\n", __FUNCTION__);
+			return -ENOMEM;
+		}
+
+		wg_dsa_bus->name   = "Marvell 886190";
+		wg_dsa_bus->priv   = wg_dsa_hw = hw;
+		wg_dsa_bus->parent = NULL;
+		wg_dsa_bus->read   = wg_ixgbe_phy_read;
+		wg_dsa_bus->write  = wg_ixgbe_phy_write;
+
+		strncpy(wg_dsa_bus->id, "88E6190", MII_BUS_ID_SIZE);
+	
+		wg_ixgbe_mdio_release();
+		wg_ixgbe_phy_init();
+		wg_ixgbe_sgmii_init(9);
+		wg_ixgbe_sgmii_init(8);
+		wg_ixgbe_mdio_release();
+
+		// Set up MDIO release function
+		wg_dsa_mdio_release = &wg_ixgbe_mdio_release;
+	}
+
+	return IXGBE_SUCCESS;
+}
+
+#endif	// WG_PLATFORM_DSA_MODULE || WG_PLATFORM_DSA
+
 /**
  * ixgbe_init_phy_ops_generic - Inits PHY function ptrs
  * @hw: pointer to the hardware structure
@@ -862,10 +1204,13 @@
 	 * speed.
 	 */
 	hw->phy.autoneg_advertised = 0;
-
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+#if (!defined(CONFIG_WG_PLATFORM_M290_T80) && !defined(CONFIG_WG_PLATFORM_M390) && \
+     !defined(CONFIG_WG_PLATFORM_M590_M690)) // for castlerock platforms
 	if (speed & IXGBE_LINK_SPEED_10GB_FULL)
 		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_10GB_FULL;
-
+#endif
 	if (speed & IXGBE_LINK_SPEED_5GB_FULL)
 		hw->phy.autoneg_advertised |= IXGBE_LINK_SPEED_5GB_FULL;
 
@@ -1269,6 +1614,9 @@
 	u8 cable_tech = 0;
 	u8 cable_spec = 0;
 	u16 enforce_sfp = 0;
+#ifdef CONFIG_WG_PLATFORM	// WG XD FBX-5815
+	struct ixgbe_adapter* adapter = (struct ixgbe_adapter*) hw->back;
+#endif
 
 	DEBUGFUNC("ixgbe_identify_sfp_module_generic");
 
@@ -1521,9 +1869,37 @@
 	}
 
 out:
+#ifdef CONFIG_WG_PLATFORM	// WG XD FBX-5815
+	// to avoid flooding of printk msgs in case the port is brought up, we will only
+	// print out info every 128 polls (4 min)
+	if ((adapter->sfp_poll_count & 0x7f) == 0x00) {
+		e_dev_info("@@ %s SFF id: %02x, sfp vendor: %06x, cable_tech: %02x, "
+			   "comp codes 1G: %02x, 10G: %02x, phy type: %04x, sfp_phy type: %04x\n",
+			   adapter->netdev->name, identifier, vendor_oui, cable_tech,
+			   comp_codes_1g, comp_codes_10g, hw->phy.type, hw->phy.sfp_type);
+	}
+	if (status == IXGBE_ERR_SFP_NOT_SUPPORTED) {
+		if ((adapter->sfp_poll_count & 0x7f) == 0x00)
+			e_dev_info("@@ SFP not supported. treat it as SFP_NOT_PRESENT ...\n");
+		status = IXGBE_ERR_SFP_NOT_PRESENT;
+		// doing the same as for tag "err_read_i2c_eeprom:"
+		hw->phy.sfp_type = ixgbe_sfp_type_not_present;
+		if (hw->phy.type != ixgbe_phy_nl) {
+			hw->phy.id = 0;
+			hw->phy.type = ixgbe_phy_unknown;
+		}
+	}
+	adapter->sfp_poll_count++;
+#endif
 	return status;
 
 err_read_i2c_eeprom:
+#ifdef CONFIG_WG_PLATFORM	// WG XD FBX-5815
+	if ((adapter->sfp_poll_count & 0x7f) == 0x00)
+		printk(KERN_WARNING "@@ %s err_read_i2c_eeprom, sfp may not exist\n",
+			   adapter->netdev->name);
+	adapter->sfp_poll_count++;
+#endif
 	hw->phy.sfp_type = ixgbe_sfp_type_not_present;
 	if (hw->phy.type != ixgbe_phy_nl) {
 		hw->phy.id = 0;
--- ixgbe-5.9.4/src/ixgbe_main.c.orig	2022-05-09 13:54:32.073991214 -0700
+++ ixgbe-5.9.4/src/ixgbe_main.c	2022-05-09 13:54:32.157987806 -0700
@@ -67,7 +67,7 @@
 
 #define RELEASE_TAG
 
-#define DRV_VERSION	"5.9.4" \
+#define DRV_VERSION	"5.9.5" \
 			DRIVERIOV DRV_HW_PERF FPGA \
 			BYPASS_TAG RELEASE_TAG
 #define DRV_SUMMARY	"Intel(R) 10GbE PCI Express Linux Network Driver"
@@ -326,6 +326,579 @@
 	clear_bit(__IXGBE_SERVICE_SCHED, &adapter->state);
 }
 
+#ifdef CONFIG_WG_PLATFORM	// WG: XD FBX-2063 Dump Tx/Rx ring Desc
+struct ixgbe_reg_info {
+	u32 ofs;
+	char *name;
+};
+
+static const struct ixgbe_reg_info ixgbe_reg_info_tbl[] = {
+
+	/* General Registers */
+	{IXGBE_CTRL, "CTRL"},
+	{IXGBE_STATUS, "STATUS"},
+	{IXGBE_CTRL_EXT, "CTRL_EXT"},
+	{IXGBE_GRC, "GRC"},
+
+	/* PCIe */
+	{IXGBE_GCR, "PCIe GCR"},
+	{IXGBE_GSCL_1, "GSCL1"},
+	{IXGBE_GSCL_2, "GSCL2"},
+	{IXGBE_GSCN_0, "GSCN0"},
+	{IXGBE_GSCN_1, "GSCN0"},
+	{IXGBE_GSCN_2, "GSCN0"},
+	{IXGBE_GSCN_3, "GSCN0"},
+	{IXGBE_FACTPS, "FACTPS"},
+
+	/* Interrupt Registers */
+	{IXGBE_PICAUSE, "PICAUSE"},
+	{IXGBE_PIENA, "PIENA"},
+	{IXGBE_EICR, "EICR"},
+	{IXGBE_EIMS, "EIMS"},
+	{IXGBE_EITR(0), "EITR"},
+	{IXGBE_GPIE, "GPIE"},
+
+	/* RX Registers */
+	{IXGBE_SRRCTL(0), "SRRCTL"},
+	{IXGBE_DCA_RXCTRL(0), "DRXCTL"},
+	{IXGBE_RDLEN(0), "RDLEN"},
+	{IXGBE_RDH(0), "RDH"},
+	{IXGBE_RDT(0), "RDT"},
+	{IXGBE_RXDCTL(0), "RXDCTL"},
+	{IXGBE_RETA(0), "RETA"},
+
+	/* TX Registers */
+	{IXGBE_TDLEN(0), "TDLEN"},
+	{IXGBE_TDH(0), "TDH"},
+	{IXGBE_TDT(0), "TDT"},
+	{IXGBE_TXDCTL(0), "TXDCTL"},
+	{IXGBE_DMATXCTL, "DMATXCTL"},
+	{IXGBE_MTQC, "MTQC"},
+	{IXGBE_TXPBSIZE(0), "TXPBSIZE"},
+	{IXGBE_MTQC, "MTQC"},
+	{IXGBE_MNGTXMAP, "MNGTXMAP"},
+	{IXGBE_TXPBTHRESH(0), "TXPBTHRESH"},
+
+	/* PHY & MAC */
+	{IXGBE_HLREG0, "HLREG0"},
+	{IXGBE_HLREG1, "HLREG1"},
+	{IXGBE_AUTOC, "AUTOC"},
+	{IXGBE_AUTOC2, "AUTOC2"},
+	{IXGBE_LINKS, "LINKS"},
+	{IXGBE_LINKS2, "LINKS2"},
+	{IXGBE_FECS1, "FECS1"},
+	{IXGBE_FECS2, "FECS2"},
+	{IXGBE_PCSS1, "PCSS1"},
+	{IXGBE_PCSS2, "PCSS2"},
+	{IXGBE_XPCSS, "XPCSS"},
+	{IXGBE_MACS, "MACS"},
+
+	/* stats */
+	{IXGBE_CRCERRS, "CRCERRS"},
+	{IXGBE_ILLERRC, "ILLERRC"},
+	{IXGBE_ERRBC, "ERRBC"},
+	{IXGBE_MPC(0), "MPC(0)"},
+	{IXGBE_MLFC, "MLFC"},
+	{IXGBE_MRFC, "RFC"},
+	{IXGBE_RLEC, "RLEC"},
+	{IXGBE_LXONTXC, "LXONTXC"},
+	{IXGBE_LXONRXCNT, "LXONRXC"},
+	{IXGBE_LXOFFTXC, "LXOFFTXC"},
+	{IXGBE_LXOFFRXCNT, "LXOFFRXC"},
+	{IXGBE_PXONTXC(0), "PXONTXC(0)"},
+	{IXGBE_PXONRXCNT(0), "PXONTXC(0)"},
+	{IXGBE_PXON2OFFCNT(0), "PXON2OFFCNT(0)"},
+	{IXGBE_PXOFFTXC(0), "PXOFFTXC(0)"},
+	{IXGBE_PXOFFRXCNT(0), "PXOFFRXCNT(0)"},
+
+	/* List Terminator */
+	{}
+};
+
+static const struct ixgbe_reg_info ixgbe_pcie_reg_tbl[] = {
+	{0x4,	"CMD REG"},
+	{0x6,	"PCI STATUS"},
+	{0x44,	"PM CTRL/STATUS"},
+
+	{0xA8,	"DEV_CTRL"},
+	{IXGBE_PCI_DEVICE_STATUS, "DEV_STATUS"},
+	{0xB0,	"LINK_CTRL"},
+	{IXGBE_PCI_LINK_STATUS, "LINK_STATUS"},
+
+	{0xC4, "DEV_CAP2L"},
+	{0xC6, "DEV_CAP2H"},
+	{IXGBE_PCI_DEVICE_CONTROL2, "DEV_CTRL2"},
+	{0xd2, "LINK_STATUS2"},
+
+	{0x100, "ADV_ERR_REP_CAP"},
+	{0x104, "Unc Err status1"},
+	{0x106, "Unc Err status2"},
+	{0x108, "Unc Err mask1"},
+	{0x10a, "Unc Err mask2"},
+	{0x10c, "U Err Sever L"},
+	{0x10e, "U Err Sever H"},
+	{0x110, "C Err status"},
+	{0x114, "C Err Mask"},
+	{0x118, "Err Cap Ctrl"},
+
+	{0x168, "SR IOV Ctrl"},
+	{0x16a, "SR IOV Status"},
+	
+	/* List Terminator */
+	{}
+};
+
+#define LOG_REG_SIZE		8		// 16 byte, 8 u16 words
+#define LOG_REG_ADDR		0x11c
+static void ixgbe_pcie_dump(struct ixgbe_hw *hw)
+{
+  struct ixgbe_reg_info *reginfo;
+
+  pr_info("PCIe Register             Value\n");
+  for (reginfo = (struct ixgbe_reg_info*) ixgbe_pcie_reg_tbl;
+	   reginfo->name; reginfo++)
+	printk(KERN_WARNING "%-24s %04x\n", reginfo->name, 
+		   IXGBE_READ_PCIE_WORD(hw, reginfo->ofs));
+
+  return;
+}
+
+
+#define REG_COUNT	8
+/*
+ * ixgbe_regdump - register printout routine
+ */
+static void ixgbe_regdump(struct ixgbe_hw *hw, struct ixgbe_reg_info *reginfo)
+{
+	int i = 0, j = 0;
+	char rname[16];
+	u32 regs[64];
+
+	switch (reginfo->ofs) {
+	case IXGBE_SRRCTL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_SRRCTL(i));
+		break;
+	case IXGBE_DCA_RXCTRL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_DCA_RXCTRL(i));
+		break;
+	case IXGBE_RDLEN(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RDLEN(i));
+		break;
+	case IXGBE_RDH(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RDH(i));
+		break;
+	case IXGBE_RDT(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RDT(i));
+		break;
+	case IXGBE_RXDCTL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RXDCTL(i));
+		break;
+	case IXGBE_RDBAL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RDBAL(i));
+		break;
+	case IXGBE_RDBAH(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RDBAH(i));
+		break;
+	case IXGBE_TDBAL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TDBAL(i));
+		break;
+	case IXGBE_TDBAH(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TDBAH(i));
+		break;
+	case IXGBE_TDLEN(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TDLEN(i));
+		break;
+	case IXGBE_TDH(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TDH(i));
+		break;
+	case IXGBE_TDT(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TDT(i));
+		break;
+	case IXGBE_TXDCTL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TXDCTL(i));
+		break;
+	case IXGBE_PXOFFTXC(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_PXOFFTXC(i));
+		break;
+	case IXGBE_PXOFFRXCNT(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_PXOFFRXCNT(i));
+		break;
+	case IXGBE_DCA_TXCTRL(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_DCA_TXCTRL(i));
+		break;
+	case IXGBE_TXPBSIZE(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TXPBSIZE(i));
+		break;
+	case IXGBE_EITR(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_EITR(i));
+		break;
+	case IXGBE_TXPBTHRESH(0):
+		for (i = 0; i < REG_COUNT; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_TXPBTHRESH(i));
+		break;
+	case IXGBE_RETA(0):
+		for (i = 0; i < 32; i++)
+			regs[i] = IXGBE_READ_REG(hw, IXGBE_RETA(i));
+		break;
+		
+	default:
+		pr_info("%-15s %08x\n", reginfo->name,
+			IXGBE_READ_REG(hw, reginfo->ofs));
+		return;
+	}
+
+	// we only want the value of the first 8 registers
+	for (i = 0; i < 1; i++) {
+		snprintf(rname, 16, "%s[%d-%d]", reginfo->name, i*8, i*8+7);
+		pr_err("%-15s", rname);
+		for (j = 0; j < 8; j++)
+			pr_cont(" %08x", regs[i*8+j]);
+		pr_cont("\n");
+	}
+}
+
+/*
+ * ixgbe_dump - Print registers, tx-rings and rx-rings
+ */
+static void ixgbe_dump(struct ixgbe_adapter *adapter)
+{
+	struct net_device *netdev = adapter->netdev;
+	struct ixgbe_hw *hw = &adapter->hw;
+	struct ixgbe_reg_info *reginfo;
+	int n = 0;
+	struct ixgbe_ring *tx_ring;
+	struct ixgbe_tx_buffer *tx_buffer;
+	union ixgbe_adv_tx_desc *tx_desc;
+	struct my_u0 { u64 a; u64 b; } *u0;
+	struct ixgbe_ring *rx_ring;
+	union ixgbe_adv_rx_desc *rx_desc;
+	struct ixgbe_rx_buffer *rx_buffer_info;
+	u32 staterr;
+	int i = 0;
+
+#define INTERVAL 4
+	int start;
+	int counter;
+	int tx_ntu_dump_done = 0;
+	int rx_ntu_dump_done = 0;
+
+	/* Print netdevice Info */
+	if (netdev) {
+		dev_info(&adapter->pdev->dev, "Net device Info\n");
+#ifdef	CONFIG_WG_KERNEL_4_14
+		pr_info("Device Name     state\n");
+		pr_info("%-15s %016lX\n",
+			netdev->name,
+			netdev->state);
+#else
+		pr_info("Device Name     state            "
+			"trans_start      last_rx\n");
+		pr_info("%-15s %016lX %016lX %016lX\n",
+			netdev->name,
+			netdev->state,
+			netdev->trans_start,
+			netdev->last_rx);
+#endif
+	}
+	
+	//dev_info(&adapter->pdev->dev, "SFP module Dump\n");
+	//wg_dump_sfp_regs(adapter);
+	ixgbe_pcie_dump(hw);
+
+	/* Print Registers */
+	dev_info(&adapter->pdev->dev, "Register Dump\n");
+	pr_info(" Register Name   Value\n");
+	for (reginfo = (struct ixgbe_reg_info *)ixgbe_reg_info_tbl;
+	     reginfo->name; reginfo++) {
+		ixgbe_regdump(hw, reginfo);
+	}
+
+	/* Print TX Ring Summary */
+	if (!netdev || !netif_running(netdev))
+		goto exit;
+
+	dev_info(&adapter->pdev->dev, "TX Rings Summary\n");
+	pr_info(" %s     %s              %s        %s\n",
+		"Queue [NTU] [NTC] [bi(ntc)->dma  ]",
+		"leng", "ntw", "timestamp");
+	for (n = 0; n < adapter->num_tx_queues; n++) {
+		tx_ring = adapter->tx_ring[n];
+		tx_buffer = &tx_ring->tx_buffer_info[tx_ring->next_to_clean];
+		pr_info(" %5d %5X %5X %016llX %08X %p %016llX\n",
+			   n, tx_ring->next_to_use, tx_ring->next_to_clean,
+			   (u64)dma_unmap_addr(tx_buffer, dma),
+			   dma_unmap_len(tx_buffer, len),
+			   tx_buffer->next_to_watch,
+			   (u64)tx_buffer->time_stamp);
+	}
+
+	dev_info(&adapter->pdev->dev, "TX Rings Dump\n");
+
+	/* Transmit Descriptor Formats
+	 *
+	 * 82598 Advanced Transmit Descriptor
+	 *   +--------------------------------------------------------------+
+	 * 0 |         Buffer Address [63:0]                                |
+	 *   +--------------------------------------------------------------+
+	 * 8 |  PAYLEN  | POPTS  | IDX | STA | DCMD  |DTYP |  RSV |  DTALEN |
+	 *   +--------------------------------------------------------------+
+	 *   63       46 45    40 39 36 35 32 31   24 23 20 19              0
+	 *
+	 * 82598 Advanced Transmit Descriptor (Write-Back Format)
+	 *   +--------------------------------------------------------------+
+	 * 0 |                          RSV [63:0]                          |
+	 *   +--------------------------------------------------------------+
+	 * 8 |            RSV           |  STA  |          NXTSEQ           |
+	 *   +--------------------------------------------------------------+
+	 *   63                       36 35   32 31                         0
+	 *
+	 * 82599+ Advanced Transmit Descriptor
+	 *   +--------------------------------------------------------------+
+	 * 0 |         Buffer Address [63:0]                                |
+	 *   +--------------------------------------------------------------+
+	 * 8 |PAYLEN  |POPTS|CC|IDX  |STA  |DCMD  |DTYP |MAC  |RSV  |DTALEN |
+	 *   +--------------------------------------------------------------+
+	 *   63     46 45 40 39 38 36 35 32 31  24 23 20 19 18 17 16 15     0
+	 *
+	 * 82599+ Advanced Transmit Descriptor (Write-Back Format)
+	 *   +--------------------------------------------------------------+
+	 * 0 |                          RSV [63:0]                          |
+	 *   +--------------------------------------------------------------+
+	 * 8 |            RSV           |  STA  |           RSV             |
+	 *   +--------------------------------------------------------------+
+	 *   63                       36 35   32 31                         0
+	 */
+
+	for (n = 0; n < adapter->num_tx_queues; n++) {
+		tx_ring = adapter->tx_ring[n];
+		pr_info("------------------------------------\n");
+		pr_info("TX QUEUE INDEX = %d\n", tx_ring->queue_index);
+		pr_info("------------------------------------\n");
+		pr_info("%s%s    %s              %s        %s          %s\n",
+			"T [desc]     [address 63:0  ] ",
+			"[PlPOIdStDDt Ln] [bi->dma       ] ",
+			"leng", "ntw", "timestamp", "bi->skb");
+
+		/* dumping 8 descriptors, 4 prior to and 4 after NTC */
+		if (tx_ring->next_to_clean >= INTERVAL)
+			start = tx_ring->next_to_clean - INTERVAL;
+		else
+			start = tx_ring->next_to_clean + tx_ring->count - INTERVAL;
+
+		tx_ntu_dump_done = 0;
+wg_txd_dump:
+		for (i = start, counter = 0;
+			tx_ring->desc && (counter < 2 * INTERVAL);
+			i++, counter++) {
+			if (i == tx_ring->count)
+				i = 0;
+			tx_desc = IXGBE_TX_DESC(tx_ring, i);
+			tx_buffer = &tx_ring->tx_buffer_info[i];
+			u0 = (struct my_u0 *)tx_desc;
+			if (dma_unmap_len(tx_buffer, len) > 0) {
+				pr_info("T [0x%03X]    %016llX %016llX %016llX %08X %p %016llX %p",
+					i,
+					le64_to_cpu(u0->a),
+					le64_to_cpu(u0->b),
+					(u64)dma_unmap_addr(tx_buffer, dma),
+					dma_unmap_len(tx_buffer, len),
+					tx_buffer->next_to_watch,
+					(u64)tx_buffer->time_stamp,
+					tx_buffer->skb);
+				if (i == tx_ring->next_to_use &&
+					i == tx_ring->next_to_clean)
+					pr_cont(" NTC/U\n");
+				else if (i == tx_ring->next_to_use)
+					pr_cont(" NTU\n");
+				else if (i == tx_ring->next_to_clean)
+					pr_cont(" NTC\n");
+				else
+					pr_cont("\n");
+
+				if (netif_msg_pktdata(adapter) &&
+				    tx_buffer->skb)
+					print_hex_dump(KERN_INFO, "",
+						DUMP_PREFIX_ADDRESS, 16, 1,
+						tx_buffer->skb->data,
+						dma_unmap_len(tx_buffer, len),
+						true);
+			}
+		}
+
+		/* dumping 8 descriptors, 4 prior to and 4 after NTU */
+		if (!tx_ntu_dump_done) {
+		  tx_ntu_dump_done = 1;
+		  printk(KERN_INFO "...\n");
+		  if (tx_ring->next_to_use >= INTERVAL)
+			start = tx_ring->next_to_use - INTERVAL;
+		  else
+			start = tx_ring->next_to_use + tx_ring->count - INTERVAL;
+
+          /* goto is not that bad in this case */
+		  goto wg_txd_dump;
+		}
+		
+	}
+
+	/* Print RX Rings Summary */
+	dev_info(&adapter->pdev->dev, "RX Rings Summary\n");
+	pr_info("Queue [NTU] [NTC]\n");
+	for (n = 0; n < adapter->num_rx_queues; n++) {
+		rx_ring = adapter->rx_ring[n];
+		pr_info("%5d %5X %5X\n",
+			n, rx_ring->next_to_use, rx_ring->next_to_clean);
+	}
+
+	dev_info(&adapter->pdev->dev, "RX Rings Dump\n");
+
+	/* Receive Descriptor Formats
+	 *
+	 * 82598 Advanced Receive Descriptor (Read) Format
+	 *    63                                           1        0
+	 *    +-----------------------------------------------------+
+	 *  0 |       Packet Buffer Address [63:1]           |A0/NSE|
+	 *    +----------------------------------------------+------+
+	 *  8 |       Header Buffer Address [63:1]           |  DD  |
+	 *    +-----------------------------------------------------+
+	 *
+	 *
+	 * 82598 Advanced Receive Descriptor (Write-Back) Format
+	 *
+	 *   63       48 47    32 31  30      21 20 16 15   4 3     0
+	 *   +------------------------------------------------------+
+	 * 0 |       RSS Hash /  |SPH| HDR_LEN  | RSV |Packet|  RSS |
+	 *   | Packet   | IP     |   |          |     | Type | Type |
+	 *   | Checksum | Ident  |   |          |     |      |      |
+	 *   +------------------------------------------------------+
+	 * 8 | VLAN Tag | Length | Extended Error | Extended Status |
+	 *   +------------------------------------------------------+
+	 *   63       48 47    32 31            20 19               0
+	 *
+	 * 82599+ Advanced Receive Descriptor (Read) Format
+	 *    63                                           1        0
+	 *    +-----------------------------------------------------+
+	 *  0 |       Packet Buffer Address [63:1]           |A0/NSE|
+	 *    +----------------------------------------------+------+
+	 *  8 |       Header Buffer Address [63:1]           |  DD  |
+	 *    +-----------------------------------------------------+
+	 *
+	 *
+	 * 82599+ Advanced Receive Descriptor (Write-Back) Format
+	 *
+	 *   63       48 47    32 31  30      21 20 17 16   4 3     0
+	 *   +------------------------------------------------------+
+	 * 0 |RSS / Frag Checksum|SPH| HDR_LEN  |RSC- |Packet|  RSS |
+	 *   |/ RTT / PCoE_PARAM |   |          | CNT | Type | Type |
+	 *   |/ Flow Dir Flt ID  |   |          |     |      |      |
+	 *   +------------------------------------------------------+
+	 * 8 | VLAN Tag | Length |Extended Error| Xtnd Status/NEXTP |
+	 *   +------------------------------------------------------+
+	 *   63       48 47    32 31          20 19                 0
+	 */
+
+	for (n = 0; n < adapter->num_rx_queues; n++) {
+		rx_ring = adapter->rx_ring[n];
+		pr_info("------------------------------------\n");
+		pr_info("RX QUEUE INDEX = %d\n", rx_ring->queue_index);
+		pr_info("------------------------------------\n");
+		pr_info("%s%s%s",
+			"R  [desc]      [ PktBuf     A0] ",
+			"[  HeadBuf   DD] [bi->dma       ] [bi->skb       ] ",
+			"<-- Adv Rx Read format\n");
+		pr_info("%s%s%s",
+			"RWB[desc]      [PcsmIpSHl PtRs] ",
+			"[vl er S cks ln] ---------------- [bi->skb       ] ",
+			"<-- Adv Rx Write-Back format\n");
+
+        /* dumping 16 descriptors, 8 prior to and 8 after NTC */
+		if (rx_ring->next_to_clean >= INTERVAL)
+			start = rx_ring->next_to_clean - INTERVAL;
+		else
+			start = rx_ring->next_to_clean + rx_ring->count - INTERVAL;
+
+		rx_ntu_dump_done = 0;
+wg_rxd_dump:
+		for (i = start, counter = 0;
+			rx_ring->desc && (counter < 2 * INTERVAL);
+			i++, counter++) {
+			if (i == rx_ring->count)
+				i = 0;
+			rx_buffer_info = &rx_ring->rx_buffer_info[i];
+			rx_desc = IXGBE_RX_DESC(rx_ring, i);
+			u0 = (struct my_u0 *)rx_desc;
+			staterr = le32_to_cpu(rx_desc->wb.upper.status_error);
+			if (staterr & IXGBE_RXD_STAT_DD) {
+				/* Descriptor Done */
+				pr_info("RWB[0x%03X]     %016llX "
+					"%016llX ---------------- %p", i,
+					le64_to_cpu(u0->a),
+					le64_to_cpu(u0->b),
+					rx_buffer_info->skb);
+			} else {
+				pr_info("R  [0x%03X]     %016llX "
+					"%016llX %016llX %p", i,
+					le64_to_cpu(u0->a),
+					le64_to_cpu(u0->b),
+					(u64)rx_buffer_info->dma,
+					rx_buffer_info->skb);
+
+				if (netif_msg_pktdata(adapter) &&
+				    rx_buffer_info->dma) {
+					print_hex_dump(KERN_INFO, "",
+					   DUMP_PREFIX_ADDRESS, 16, 1,
+					   page_address(rx_buffer_info->page) +
+						    rx_buffer_info->page_offset,
+					   ixgbe_rx_bufsz(rx_ring), true);
+				}
+			}
+
+			if (i == rx_ring->next_to_use)
+				pr_cont(" NTU\n");
+			else if (i == rx_ring->next_to_clean)
+				pr_cont(" NTC\n");
+			else
+				pr_cont("\n");
+
+		}
+
+		/* dumping 16 descriptors, 8 prior to and 8 after NTU */
+		if (!rx_ntu_dump_done) {
+			rx_ntu_dump_done = 1;
+			printk(KERN_INFO "...\n");
+			if (rx_ring->next_to_use >= INTERVAL)
+				start = rx_ring->next_to_use - INTERVAL;
+			else
+				start = rx_ring->next_to_use + rx_ring->count - INTERVAL;
+
+          /* goto is not that bad in this case */
+			goto wg_rxd_dump;
+		}
+	}
+
+exit:
+	return;
+}
+#endif	// WG: XD FBX-2063 Dump Tx/Rx ring Desc
+
 static void ixgbe_remove_adapter(struct ixgbe_hw *hw)
 {
 	struct ixgbe_adapter *adapter = hw->back;
@@ -672,6 +1245,9 @@
 
 	/* Do the reset outside of interrupt context */
 	if (!test_bit(__IXGBE_DOWN, &adapter->state)) {
+#ifdef CONFIG_WG_PLATFORM     // WG XD FBX-11087
+		set_bit(__IXGBE_TX_HUNG_TIMEO, &adapter->state);
+#endif
 		set_bit(__IXGBE_RESET_REQUESTED, &adapter->state);
 		ixgbe_service_event_schedule(adapter);
 	}
@@ -852,6 +1428,12 @@
 		       "tx hang %d detected on queue %d, resetting adapter\n",
 		       adapter->tx_timeout_count + 1, tx_ring->queue_index);
 
+#ifdef	CONFIG_WG_PLATFORM // WG:XD FBX-2063
+		ixgbe_dump(adapter);
+		mdelay(1500);
+		printk(KERN_WARNING "@@ %s 2nd dump ...\n", adapter->netdev->name);
+		ixgbe_dump(adapter);
+#endif
 		ixgbe_tx_timeout_reset(adapter);
 
 		/* the adapter is about to reset, no point in enabling stuff */
@@ -1513,6 +2095,11 @@
 #endif
 }
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+// DSA SW devices
+extern struct net_device* wg_dsa_dev[2];
+#endif
+
 /**
  * ixgbe_process_skb_fields - Populate skb header fields from Rx descriptor
  * @rx_ring: rx descriptor ring packet is being transacted on
@@ -1766,7 +2353,19 @@
 
 	/* place header in linear portion of buffer */
 	if (!skb_headlen(skb))
+#ifdef	CONFIG_WG_PLATFORM_IGB_LINEARIZE // WG:JB skb linearize
+	{
+		if (likely(!wg_dsa_dev[0]))
+			igb_pull_tail(skb);
+		else
+			if (skb_linearize(skb)) {
+				dev_kfree_skb_any(skb);
+				return true;
+			}
+	}
+#else
 		ixgbe_pull_tail(skb);
+#endif
 
 #if IS_ENABLED(CONFIG_FCOE)
 	/* do not attempt to pad FCoE Frames as this will disrupt DDP */
@@ -3944,7 +4543,19 @@
 		if (unlikely(!rss_key))
 			return -ENOMEM;
 
+#ifdef CONFIG_WG_PLATFORM	// FBX-11388 the seed value is from v4.1.5 driver
+	{
+		int i;
+		const u32 seed[10] = {0xE291D73D, 0x1805EC6C, 0x2A94B30D,
+							  0xA54F2BEC, 0xEA49AF7C, 0xE214AD3D, 0xB855AABE,
+							  0x6A3E67EA, 0x14364D17, 0x3BED200D};
+		printk(KERN_WARNING "@@ %s filling rss_keys ...\n", adapter->netdev->name);
+		for (i = 0; i < 10; i++)
+			rss_key[i] = seed[i];
+	}
+#else
 		netdev_rss_key_fill(rss_key, IXGBE_RSS_KEY_SIZE);
+#endif
 		adapter->rss_key = rss_key;
 	}
 
@@ -5141,6 +5752,21 @@
 	enable = !!(features & NETIF_F_HW_VLAN_RX);
 #endif /* NETIF_F_HW_VLAN_CTAG_RX */
 #endif /* HAVE_VLAN_RX_REGISTER */
+
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) // WG:JB Disable VLAN assist if Marvell headers
+	if (unlikely(wg_dsa_dev[0])) {
+		struct ixgbe_hw *hw = &adapter->hw;
+		u32 vlnctrl;
+		/* disable VLAN tag insert/strip */
+		vlnctrl  =  IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+		vlnctrl &= ~IXGBE_VLNCTRL_VME;
+		IXGBE_WRITE_REG(hw, IXGBE_VLNCTRL, vlnctrl);
+		printk(KERN_INFO "%s: Blocking HW_VLAN_CTAG_RX on %s\n",
+		       __FUNCTION__, netdev->name);
+		return;
+	}
+#endif
+
 	if (enable)
 		/* enable VLAN tag insert/strip */
 		ixgbe_vlan_strip_enable(adapter);
@@ -5566,6 +6192,11 @@
 		IXGBE_WRITE_REG(hw, IXGBE_VMOLR(VMDQ_P(0)), vmolr);
 	}
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) // WG:JB SW devices get special modes
+	if (has88E6190)
+		fctrl |= (IXGBE_FCTRL_UPE | IXGBE_FCTRL_MPE | IXGBE_FCTRL_SBP);
+#endif
+
 	IXGBE_WRITE_REG(hw, IXGBE_FCTRL, fctrl);
 
 #ifdef HAVE_8021P_SUPPORT
@@ -6581,6 +7212,17 @@
 	adapter->netdev->trans_start = jiffies;
 #endif
 
+#ifdef CONFIG_WG_PLATFORM	// WG: XD FBX-2063 Dump Tx/Rx ring Desc
+	if (test_bit(__IXGBE_TX_HUNG_TIMEO, &adapter->state)) {	//	FBX-11087
+		printk(KERN_WARNING "@@ %s reseting %s ...\n", __FUNCTION__, adapter->netdev->name);
+		ixgbe_dump(adapter);
+		mdelay(1500);
+		printk(KERN_WARNING "@@ %s 2nd dump ...\n", adapter->netdev->name);
+		ixgbe_dump(adapter);
+		clear_bit(__IXGBE_TX_HUNG_TIMEO, &adapter->state);
+	}
+#endif
+
 	while (test_and_set_bit(__IXGBE_RESETTING, &adapter->state))
 		usleep_range(1000, 2000);
 	if (adapter->hw.phy.type == ixgbe_phy_fw)
@@ -7018,7 +7660,9 @@
 void ixgbe_down(struct ixgbe_adapter *adapter)
 {
 	struct net_device *netdev = adapter->netdev;
+#ifndef	CONFIG_WG_PLATFORM // WG:XD Fix for BUG77152
 	struct ixgbe_hw *hw = &adapter->hw;
+#endif
 	int i;
 
 	/* signal that we are down to the interrupt handler */
@@ -7072,12 +7716,18 @@
 #endif
 		ixgbe_reset(adapter);
 
+#ifndef	CONFIG_WG_PLATFORM // WG:XD Fix for BUG77152
 	/* power down the optics for 82599 SFP+ fiber */
 	if (hw->mac.ops.disable_tx_laser)
 		hw->mac.ops.disable_tx_laser(hw);
+#endif
 
 	ixgbe_clean_all_tx_rings(adapter);
 	ixgbe_clean_all_rx_rings(adapter);
+#ifdef CONFIG_WG_PLATFORM	// WG XD FBX-5815, FBX-11087
+	adapter->sfp_poll_count = 0;
+	clear_bit(__IXGBE_TX_HUNG_TIMEO, &adapter->state);
+#endif
 }
 
 /**
@@ -7666,6 +8316,16 @@
 	struct ixgbe_adapter *adapter = netdev_priv(netdev);
 #ifndef HAVE_NETDEVICE_MIN_MAX_MTU
 	int max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN;
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+	if (has88E6190) {
+		if (max_frame < (VLAN_ETH_FRAME_LEN + ETH_FCS_LEN))
+		    max_frame = (VLAN_ETH_FRAME_LEN + ETH_FCS_LEN);
+		max_frame += 4;
+	}
+
+	printk(KERN_INFO "%s: %-5s MTU %d Max Frame %d\n",
+	       __FUNCTION__, netdev->name, new_mtu, max_frame);
+#endif
 #endif
 
 	if (adapter->xdp_prog) {
@@ -7780,6 +8440,10 @@
 #elif defined(HAVE_VXLAN_RX_OFFLOAD)
 	vxlan_get_rx_port(netdev);
 #endif /* HAVE_UDP_ENC_RX_OFFLOAD */
+#ifdef CONFIG_WG_PLATFORM	// WG XD FBX-5815, FBX-11087
+	adapter->sfp_poll_count = 0;
+	clear_bit(__IXGBE_TX_HUNG_TIMEO, &adapter->state);
+#endif
 	return IXGBE_SUCCESS;
 
 err_set_queues:
@@ -7838,6 +8502,10 @@
 {
 	struct ixgbe_adapter *adapter = netdev_priv(netdev);
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+	wg_dsa_sgmii_poll = NULL;
+#endif
+
 #ifdef HAVE_PTP_1588_CLOCK
 	ixgbe_ptp_stop(adapter);
 #endif
@@ -10410,6 +11078,23 @@
 	prtad = (mii->phy_id & MDIO_PHY_ID_PRTAD) >> 5;
 	devad = (mii->phy_id & MDIO_PHY_ID_DEVAD);
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)
+	if (has88E6190) {
+		mutex_lock(&wg_dsa_mutex);
+		if (cmd == SIOCGMIIREG) {
+			ret = wg_dsa_bus->read(wg_dsa_bus, prtad, mii->reg_num);
+			if (ret >= 0) {
+				mii->val_out = ret;
+				ret = 0;
+			}
+		} else
+			ret = wg_dsa_bus->write(wg_dsa_bus, prtad, mii->reg_num,
+									mii->val_in);
+		mutex_unlock(&wg_dsa_mutex);
+		return ret;
+	}
+#endif
+
 	if (cmd == SIOCGMIIREG) {
 		ret = ixgbe_mdio_read(netdev, prtad, devad, mii->reg_num);
 		if (ret < 0)
@@ -12293,6 +12978,40 @@
 		 "0x%08x", etrack_id);
 }
 
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+// CL # 506558 is intended for T80 only. CONFIG_WG_ARCH_ARM_64 will also affect
+// M290, M390, M590 and M690. Replace with CONFIG_WG_PLATFORM_T80 instead
+#ifdef CONFIG_WG_ARCH_ARM_64	// the original #def for CL # 506588
+#if (defined(CONFIG_WG_PLATFORM_DSA_MODE_T80) && \
+	!defined(CONFIG_WG_PLATFORM_M290_T80) && \
+	!defined(CONFIG_WG_PLATFORM_M390) && \
+	!defined(CONFIG_WG_PLATFORM_M590_M690))
+#define CONFIG_WG_PLATFORM_T80
+#endif
+#endif	// CONFIG_WG_ARCH_ARM_64
+
+#ifdef CONFIG_WG_PLATFORM_T80
+static int ixgbe_readMacAddrFromEEprom(struct ixgbe_hw *hw, struct ixgbe_adapter *adapter)
+{
+	int first_word, eeprom_len;
+	int i;
+	u16 eeprom_buff[3] = {0};
+
+	first_word = 0x11; /* Offset 0x11 - 0x13 in Word */
+	eeprom_len = 6>>1; /* length is word size */
+	if (hw->eeprom.ops.read_buffer(hw, first_word, eeprom_len, eeprom_buff) < 0) {
+		e_dev_err("Failed to read The EEPROM!!!\n");
+		return -EIO;
+	}
+	for (i = 0; i < eeprom_len; i++)
+		le16_to_cpus(&eeprom_buff[i]);
+	memcpy(hw->mac.perm_addr, eeprom_buff, 6);
+
+	return 0;
+}
+#endif /* CONFIG_WG_PLATFORM_T80 */
+
 /**
  * ixgbe_probe - Device Initialization Routine
  * @pdev: PCI device information struct
@@ -12337,6 +13056,23 @@
 #endif
 #endif /* NETIF_F_GSO_PARTIAL */
 	int i;
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+#if defined(CONFIG_WG_PLATFORM_M290_T80) || defined(CONFIG_WG_PLATFORM_M390) || \
+    defined(CONFIG_WG_PLATFORM_M590_M690) // for castlerock platforms
+	u16 phy_data; /* FBX-21014 */
+#endif
+
+#ifdef CONFIG_WG_PLATFORM_T80
+	u8 defaultMac[6] = {0x12, 0x34, 0x56, 0x78, 0x90, 0xab};
+#endif 
+
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) // WG:JB Only use Device ID 15C2 with 88E6190
+	if (has88E6190) {
+		static int eths = 0;
+		if (++eths > 2) return -ENODEV;
+	}
+#endif
 	err = pci_enable_device_mem(pdev);
 	if (err)
 		return err;
@@ -12482,6 +13218,11 @@
 	 */
 	ixgbe_check_options(adapter);
 
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) // WG:JB If we have a MV88E6190 switch use only 1 RSS queue
+	if (has88E6190)
+		adapter->ring_feature[RING_F_RSS].limit = 1;
+#endif
+
 	/* reset_hw fills in the perm_addr as well */
 	hw->phy.reset_if_overtemp = true;
 	err = hw->mac.ops.reset_hw(hw);
@@ -12744,11 +13485,27 @@
 		goto err_sw_init;
 	}
 
+#ifdef CONFIG_WG_PLATFORM_T80
+	if (ixgbe_readMacAddrFromEEprom(hw, adapter) < 0) {
+		e_dev_err("The EEPROM MAC Address Is Not Valid\n");
+		err = -EIO;
+		goto err_sw_init;
+	}
+#else
 	memcpy(netdev->dev_addr, hw->mac.perm_addr, netdev->addr_len);
+#endif /* CONFIG_WG_PLATFORM_T80 */
 #ifdef ETHTOOL_GPERMADDR
 	memcpy(netdev->perm_addr, hw->mac.perm_addr, netdev->addr_len);
 #endif
 
+#ifdef CONFIG_WG_PLATFORM_T80
+	if (!is_valid_ether_addr(hw->mac.perm_addr)) {
+		memcpy(hw->mac.perm_addr, defaultMac, 6);
+		memcpy(netdev->dev_addr, hw->mac.perm_addr, netdev->addr_len);
+	}
+	pr_info("MAC Address : %02x:%02x:%02x:%02x:%02x:%02x\n",
+		hw->mac.perm_addr[0], hw->mac.perm_addr[1], hw->mac.perm_addr[2], hw->mac.perm_addr[3], hw->mac.perm_addr[4], hw->mac.perm_addr[5]);
+#endif
 	if (!is_valid_ether_addr(netdev->dev_addr)) {
 		e_dev_err("invalid MAC address\n");
 		err = -EIO;
@@ -12828,9 +13585,11 @@
 
 #endif
 
+#ifndef	CONFIG_WG_PLATFORM // WG:XD Fix for BUG77152
 	/* power down the optics for 82599 SFP+ fiber */
 	if (hw->mac.ops.disable_tx_laser)
 		hw->mac.ops.disable_tx_laser(hw);
+#endif
 
 	/* carrier off reporting is important to ethtool even BEFORE open */
 	netif_carrier_off(netdev);
@@ -12944,6 +13703,23 @@
 	ixgbe_dbg_adapter_init(adapter);
 #endif /* HAVE_IXGBE_DEBUG_FS */
 
+/* MJampala: CONFIG_WG_PLATFORM_T85 is set so that it automatically selects
+            CONFIG_WG_PLATFORM_M290_T80. So, CONFIG_WG_PLATFORM_M290_T80 is true for T85 */
+#if defined(CONFIG_WG_PLATFORM_M290_T80) || defined(CONFIG_WG_PLATFORM_M390) || \
+    defined(CONFIG_WG_PLATFORM_M590_M690) // for castlerock platforms
+	hw->mac.ops.setup_link(hw,
+		IXGBE_LINK_SPEED_5GB_FULL | IXGBE_LINK_SPEED_2_5GB_FULL | IXGBE_LINK_SPEED_1GB_FULL | IXGBE_LINK_SPEED_100_FULL,
+			true);
+
+	/* Talor Lin [FBX-21014]: We need to additionally set a phy register(0xe400):bit0 (See x550 datasheet 10.2.45 for details) to 0 */
+	hw->phy.ops.read_reg(hw, 0xe400, IXGBE_MDIO_PMA_PMD_DEV_TYPE, &phy_data);
+	/* printk("(1)Func %s: line %d, phy_data = 0x%x.\n", __func__, __LINE__, phy_data); */
+	phy_data &= 0xfffe;
+	hw->phy.ops.write_reg(hw, 0xe400, IXGBE_MDIO_PMA_PMD_DEV_TYPE, phy_data);
+	/* hw->phy.ops.read_reg(hw, 0xe400, IXGBE_MDIO_PMA_PMD_DEV_TYPE, &phy_data);
+	   printk("(2)Func %s: line %d, phy_data = 0x%x.\n", __func__, __LINE__, phy_data); */
+	/* End of FBX-21014 */
+#endif
 	/* setup link for SFP devices with MNG FW, else wait for IXGBE_UP */
 	if (ixgbe_mng_enabled(hw) && ixgbe_is_sfp(hw) && hw->mac.ops.setup_link)
 		hw->mac.ops.setup_link(hw,
--- ixgbe-5.9.4/src/ixgbe_common.c.orig	2022-05-09 13:54:31.993994459 -0700
+++ ixgbe-5.9.4/src/ixgbe_common.c	2022-05-09 13:54:32.145988293 -0700
@@ -2632,7 +2632,15 @@
 	}
 
 	/* Set 802.3x based flow control settings. */
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) 	// WG:XD FBX-156516
+	if (has88E6190) {		// will affect plaforms that have 88e6190 switches only
+		mflcn_reg &= ~IXGBE_MFLCN_DPF;
+		mflcn_reg |= IXGBE_MFLCN_PMCF;
+	} else					// keep the original behavior
+		mflcn_reg |= IXGBE_MFLCN_DPF;
+#else
 	mflcn_reg |= IXGBE_MFLCN_DPF;
+#endif
 	IXGBE_WRITE_REG(hw, IXGBE_MFLCN, mflcn_reg);
 	IXGBE_WRITE_REG(hw, IXGBE_FCCFG, fccfg_reg);
 
--- ixgbe-5.9.4/src/ixgbe.h.orig	2022-05-09 13:54:31.933996894 -0700
+++ ixgbe-5.9.4/src/ixgbe.h	2022-05-09 13:54:32.137988618 -0700
@@ -1079,20 +1079,35 @@
 	u16 num_xsk_umems_used;
 	u16 num_xsk_umems;
 #endif
+#ifdef CONFIG_WG_PLATFORM // WG XD FBX-5815
+	unsigned int sfp_poll_count;	// for avoiding flooding printk message only
+#endif
 };
 
+#ifdef	CONFIG_WG_PLATFORM // WG:JB Limit RSS if we have too many CPUs
+u8	wg_max_rss(struct ixgbe_adapter *adapter, int q);
+#endif
+
 static inline u8 ixgbe_max_rss_indices(struct ixgbe_adapter *adapter)
 {
 	switch (adapter->hw.mac.type) {
 	case ixgbe_mac_82598EB:
 	case ixgbe_mac_82599EB:
 	case ixgbe_mac_X540:
+#ifdef	CONFIG_WG_PLATFORM // WG:JB Limit RSS if we have too many CPUs
+		return wg_max_rss(adapter, IXGBE_MAX_RSS_INDICES);
+#else
 		return IXGBE_MAX_RSS_INDICES;
+#endif
 		break;
 	case ixgbe_mac_X550:
 	case ixgbe_mac_X550EM_x:
 	case ixgbe_mac_X550EM_a:
+#ifdef	CONFIG_WG_PLATFORM // WG:JB Limit RSS if we have too many CPUs
+		return wg_max_rss(adapter, IXGBE_MAX_RSS_INDICES_X550);
+#else
 		return IXGBE_MAX_RSS_INDICES_X550;
+#endif
 		break;
 	default:
 		return 0;
@@ -1121,6 +1136,9 @@
 	__IXGBE_PTP_TX_IN_PROGRESS,
 #endif
 	__IXGBE_RESET_REQUESTED,
+#ifdef CONFIG_WG_PLATFORM	// WG: XD FBX-11087
+	__IXGBE_TX_HUNG_TIMEO,	// Tx hung or timeout occurred
+#endif
 };
 
 struct ixgbe_cb {
--- ixgbe-5.9.4/src/ixgbe_x550.c.orig	2022-05-09 13:54:32.113989591 -0700
+++ ixgbe-5.9.4/src/ixgbe_x550.c	2022-05-09 13:54:32.165987482 -0700
@@ -306,6 +306,100 @@
 	IXGBE_WRITE_FLUSH(hw);
 }
 
+// WG:XD WG Patches for M270 still need the API's
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA)/**
+ * ixgbe_read_phy_reg_mdi_22 - Read from a clause 22 PHY register without lock
+ * @hw: pointer to hardware structure
+ * @reg_addr: 32 bit address of PHY register to read
+ * @dev_type: always unused
+ * @phy_data: Pointer to read data from PHY register
+ */
+STATIC s32 ixgbe_read_phy_reg_mdi_22(struct ixgbe_hw *hw, u32 reg_addr,
+				     u32 dev_type, u16 *phy_data)
+{
+	u32 i, data, command;
+	UNREFERENCED_1PARAMETER(dev_type);
+
+	/* Setup and write the read command */
+	command = (reg_addr << IXGBE_MSCA_DEV_TYPE_SHIFT) |
+		  (hw->phy.addr << IXGBE_MSCA_PHY_ADDR_SHIFT) |
+		  IXGBE_MSCA_OLD_PROTOCOL | IXGBE_MSCA_READ_AUTOINC |
+		  IXGBE_MSCA_MDI_COMMAND;
+
+	IXGBE_WRITE_REG(hw, IXGBE_MSCA, command);
+
+	/* Check every 10 usec to see if the access completed.
+	 * The MDI Command bit will clear when the operation is
+	 * complete
+	 */
+	for (i = 0; i < IXGBE_MDIO_COMMAND_TIMEOUT; i++) {
+		usec_delay(10);
+
+		command = IXGBE_READ_REG(hw, IXGBE_MSCA);
+		if (!(command & IXGBE_MSCA_MDI_COMMAND))
+			break;
+	}
+
+	if (command & IXGBE_MSCA_MDI_COMMAND) {
+		ERROR_REPORT1(IXGBE_ERROR_POLLING,
+			      "PHY read command did not complete.\n");
+		return IXGBE_ERR_PHY;
+	}
+
+	/* Read operation is complete.  Get the data from MSRWD */
+	data = IXGBE_READ_REG(hw, IXGBE_MSRWD);
+	data >>= IXGBE_MSRWD_READ_DATA_SHIFT;
+	*phy_data = (u16)data;
+
+	return IXGBE_SUCCESS;
+}
+
+/**
+ * ixgbe_write_phy_reg_mdi_22 - Write to a clause 22 PHY register without lock
+ * @hw: pointer to hardware structure
+ * @reg_addr: 32 bit PHY register to write
+ * @dev_type: always unused
+ * @phy_data: Data to write to the PHY register
+ */
+STATIC s32 ixgbe_write_phy_reg_mdi_22(struct ixgbe_hw *hw, u32 reg_addr,
+				      u32 dev_type, u16 phy_data)
+{
+	u32 i, command;
+	UNREFERENCED_1PARAMETER(dev_type);
+
+	/* Put the data in the MDI single read and write data register*/
+	IXGBE_WRITE_REG(hw, IXGBE_MSRWD, (u32)phy_data);
+
+	/* Setup and write the write command */
+	command = (reg_addr << IXGBE_MSCA_DEV_TYPE_SHIFT) |
+		  (hw->phy.addr << IXGBE_MSCA_PHY_ADDR_SHIFT) |
+		  IXGBE_MSCA_OLD_PROTOCOL | IXGBE_MSCA_WRITE |
+		  IXGBE_MSCA_MDI_COMMAND;
+
+	IXGBE_WRITE_REG(hw, IXGBE_MSCA, command);
+
+	/* Check every 10 usec to see if the access completed.
+	 * The MDI Command bit will clear when the operation is
+	 * complete
+	 */
+	for (i = 0; i < IXGBE_MDIO_COMMAND_TIMEOUT; i++) {
+		usec_delay(10);
+
+		command = IXGBE_READ_REG(hw, IXGBE_MSCA);
+		if (!(command & IXGBE_MSCA_MDI_COMMAND))
+			break;
+	}
+
+	if (command & IXGBE_MSCA_MDI_COMMAND) {
+		ERROR_REPORT1(IXGBE_ERROR_POLLING,
+			      "PHY write cmd didn't complete\n");
+		return IXGBE_ERR_PHY;
+	}
+
+	return IXGBE_SUCCESS;
+}
+#endif // WG_PLATFORM_DSA_MODULE || WG_PLATFORM_DSA
+
 /**
  * ixgbe_identify_phy_x550em - Get PHY type based on device id
  * @hw: pointer to hardware structure
@@ -2312,6 +2406,21 @@
 		phy->ops.setup_link = ixgbe_setup_kr_x550em;
 		phy->ops.read_reg = ixgbe_read_phy_reg_x550em;
 		phy->ops.write_reg = ixgbe_write_phy_reg_x550em;
+// WG:JB Fix for MDIO issue from Lanner
+#if defined(CONFIG_WG_PLATFORM_DSA_MODULE) || defined (CONFIG_WG_PLATFORM_DSA) 
+		if (unlikely(has88E6190)) {
+
+		void ixgbe_init_88E6190(struct ixgbe_hw*);
+
+		phy->ops.read_reg_mdi = ixgbe_read_phy_reg_mdi_22;
+		phy->ops.write_reg_mdi = ixgbe_write_phy_reg_mdi_22;
+		phy->ops.read_reg = ixgbe_read_phy_reg_x550a;
+		phy->ops.write_reg = ixgbe_write_phy_reg_x550a;
+
+		ixgbe_init_88E6190(hw);
+
+		}
+#endif
 		break;
 	case ixgbe_phy_ext_1g_t:
 		/* link is managed by FW */
